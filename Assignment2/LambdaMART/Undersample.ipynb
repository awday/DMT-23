{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time 1.3387375950813294\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_id</th>\n",
       "      <th>date_time</th>\n",
       "      <th>site_id</th>\n",
       "      <th>visitor_location_country_id</th>\n",
       "      <th>visitor_hist_starrating</th>\n",
       "      <th>visitor_hist_adr_usd</th>\n",
       "      <th>prop_country_id</th>\n",
       "      <th>prop_id</th>\n",
       "      <th>prop_starrating</th>\n",
       "      <th>prop_review_score</th>\n",
       "      <th>...</th>\n",
       "      <th>comp6_rate_percent_diff</th>\n",
       "      <th>comp7_rate</th>\n",
       "      <th>comp7_inv</th>\n",
       "      <th>comp7_rate_percent_diff</th>\n",
       "      <th>comp8_rate</th>\n",
       "      <th>comp8_inv</th>\n",
       "      <th>comp8_rate_percent_diff</th>\n",
       "      <th>click_bool</th>\n",
       "      <th>gross_bookings_usd</th>\n",
       "      <th>booking_bool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>10404</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>21315</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>27348</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>29604</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   srch_id            date_time  site_id  visitor_location_country_id  \\\n",
       "0        1  2013-04-04 08:32:15       12                          187   \n",
       "1        1  2013-04-04 08:32:15       12                          187   \n",
       "2        1  2013-04-04 08:32:15       12                          187   \n",
       "3        1  2013-04-04 08:32:15       12                          187   \n",
       "4        1  2013-04-04 08:32:15       12                          187   \n",
       "\n",
       "   visitor_hist_starrating  visitor_hist_adr_usd  prop_country_id  prop_id  \\\n",
       "0                      NaN                   NaN              219      893   \n",
       "1                      NaN                   NaN              219    10404   \n",
       "2                      NaN                   NaN              219    21315   \n",
       "3                      NaN                   NaN              219    27348   \n",
       "4                      NaN                   NaN              219    29604   \n",
       "\n",
       "   prop_starrating  prop_review_score      ...       comp6_rate_percent_diff  \\\n",
       "0                3                3.5      ...                           NaN   \n",
       "1                4                4.0      ...                           NaN   \n",
       "2                3                4.5      ...                           NaN   \n",
       "3                2                4.0      ...                           NaN   \n",
       "4                4                3.5      ...                           NaN   \n",
       "\n",
       "   comp7_rate  comp7_inv  comp7_rate_percent_diff  comp8_rate  comp8_inv  \\\n",
       "0         NaN        NaN                      NaN         0.0        0.0   \n",
       "1         NaN        NaN                      NaN         0.0        0.0   \n",
       "2         NaN        NaN                      NaN         0.0        0.0   \n",
       "3         NaN        NaN                      NaN        -1.0        0.0   \n",
       "4         NaN        NaN                      NaN         0.0        0.0   \n",
       "\n",
       "   comp8_rate_percent_diff  click_bool  gross_bookings_usd  booking_bool  \n",
       "0                      NaN           0                 NaN             0  \n",
       "1                      NaN           0                 NaN             0  \n",
       "2                      NaN           0                 NaN             0  \n",
       "3                      5.0           0                 NaN             0  \n",
       "4                      NaN           0                 NaN             0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to sample queries\n",
    "def sample_queries(df, frac):\n",
    "    srch_ids = pd.Series(df[\"srch_id\"].unique()).sample(frac=frac, random_state=42)\n",
    "    return df.loc[df.srch_id.isin(srch_ids)]\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "in_train = pd.read_csv(\"data/training_set_VU_DM_2014.csv\")\n",
    "#in_test = pd.read_csv(\"data/testing_set_VU_DM_2014.csv\")\n",
    "in_test = pd.read_csv(\"data/kaggle_test.csv\")\n",
    "#in_test = in_train.drop([\"click_bool\", \"booking_bool\", \"position\", \"gross_bookings_usd\"], axis=1).head(n=0)\n",
    "\n",
    "# Speed up execution\n",
    "#in_train = sample_queries(in_train, 0.1)\n",
    "\n",
    "print(\"Elapsed time\", (time.time() - start)/60)\n",
    "in_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time 3.1175362626711527\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_id</th>\n",
       "      <th>date_time</th>\n",
       "      <th>site_id</th>\n",
       "      <th>visitor_location_country_id</th>\n",
       "      <th>visitor_hist_starrating</th>\n",
       "      <th>visitor_hist_adr_usd</th>\n",
       "      <th>prop_country_id</th>\n",
       "      <th>prop_id</th>\n",
       "      <th>prop_starrating</th>\n",
       "      <th>prop_review_score</th>\n",
       "      <th>...</th>\n",
       "      <th>dest_std_prop_starrating</th>\n",
       "      <th>dest_mean_prop_review_score</th>\n",
       "      <th>dest_median_prop_review_score</th>\n",
       "      <th>dest_std_prop_review_score</th>\n",
       "      <th>prop_mean_price_usd</th>\n",
       "      <th>prop_median_price_usd</th>\n",
       "      <th>prop_std_price_usd</th>\n",
       "      <th>prop_mean_prop_review_score</th>\n",
       "      <th>prop_median_prop_review_score</th>\n",
       "      <th>prop_std_prop_review_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.813616</td>\n",
       "      <td>3.760563</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.7554</td>\n",
       "      <td>118.758742</td>\n",
       "      <td>118.0</td>\n",
       "      <td>17.778734</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>10404</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.813616</td>\n",
       "      <td>3.760563</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.7554</td>\n",
       "      <td>152.054082</td>\n",
       "      <td>129.0</td>\n",
       "      <td>390.928573</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>21315</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.813616</td>\n",
       "      <td>3.760563</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.7554</td>\n",
       "      <td>168.540871</td>\n",
       "      <td>165.0</td>\n",
       "      <td>345.479493</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>27348</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.813616</td>\n",
       "      <td>3.760563</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.7554</td>\n",
       "      <td>82.598870</td>\n",
       "      <td>65.1</td>\n",
       "      <td>305.765579</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-04 08:32:15</td>\n",
       "      <td>12</td>\n",
       "      <td>187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219</td>\n",
       "      <td>29604</td>\n",
       "      <td>4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.813616</td>\n",
       "      <td>3.760563</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.7554</td>\n",
       "      <td>137.648135</td>\n",
       "      <td>117.0</td>\n",
       "      <td>433.301637</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   srch_id            date_time  site_id  visitor_location_country_id  \\\n",
       "0        1  2013-04-04 08:32:15       12                          187   \n",
       "1        1  2013-04-04 08:32:15       12                          187   \n",
       "2        1  2013-04-04 08:32:15       12                          187   \n",
       "3        1  2013-04-04 08:32:15       12                          187   \n",
       "4        1  2013-04-04 08:32:15       12                          187   \n",
       "\n",
       "   visitor_hist_starrating  visitor_hist_adr_usd  prop_country_id  prop_id  \\\n",
       "0                      NaN                   NaN              219      893   \n",
       "1                      NaN                   NaN              219    10404   \n",
       "2                      NaN                   NaN              219    21315   \n",
       "3                      NaN                   NaN              219    27348   \n",
       "4                      NaN                   NaN              219    29604   \n",
       "\n",
       "   prop_starrating  prop_review_score             ...              \\\n",
       "0                3                3.5             ...               \n",
       "1                4                4.0             ...               \n",
       "2                3                4.5             ...               \n",
       "3                2                4.0             ...               \n",
       "4                4                3.5             ...               \n",
       "\n",
       "   dest_std_prop_starrating  dest_mean_prop_review_score  \\\n",
       "0                  0.813616                     3.760563   \n",
       "1                  0.813616                     3.760563   \n",
       "2                  0.813616                     3.760563   \n",
       "3                  0.813616                     3.760563   \n",
       "4                  0.813616                     3.760563   \n",
       "\n",
       "   dest_median_prop_review_score  dest_std_prop_review_score  \\\n",
       "0                            4.0                      0.7554   \n",
       "1                            4.0                      0.7554   \n",
       "2                            4.0                      0.7554   \n",
       "3                            4.0                      0.7554   \n",
       "4                            4.0                      0.7554   \n",
       "\n",
       "   prop_mean_price_usd  prop_median_price_usd  prop_std_price_usd  \\\n",
       "0           118.758742                  118.0           17.778734   \n",
       "1           152.054082                  129.0          390.928573   \n",
       "2           168.540871                  165.0          345.479493   \n",
       "3            82.598870                   65.1          305.765579   \n",
       "4           137.648135                  117.0          433.301637   \n",
       "\n",
       "   prop_mean_prop_review_score  prop_median_prop_review_score  \\\n",
       "0                          3.5                            3.5   \n",
       "1                          4.0                            4.0   \n",
       "2                          4.5                            4.5   \n",
       "3                          4.0                            4.0   \n",
       "4                          3.5                            3.5   \n",
       "\n",
       "   prop_std_prop_review_score  \n",
       "0                         0.0  \n",
       "1                         0.0  \n",
       "2                         0.0  \n",
       "3                         0.0  \n",
       "4                         0.0  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Add mean, median and std per property for a variety of numericals\n",
    "def add_mean_median_std_per_factor(df, factor, numerical, prefix):\n",
    "    grouped = df.groupby(factor)[numerical]\n",
    "    mean_by_factor = grouped.mean().to_dict()\n",
    "    median_by_factor = grouped.median().to_dict()\n",
    "    std_by_factor = grouped.std().to_dict()\n",
    "    \n",
    "    df[prefix + \"_mean_\" + numerical] = df[factor].map(lambda f: mean_by_factor[f])\n",
    "    df[prefix + \"_median_\" + numerical] = df[factor].map(lambda f: median_by_factor[f])\n",
    "    df[prefix + \"_std_\" + numerical] = df[factor].map(lambda f: std_by_factor[f])\n",
    "    \n",
    "for df in [in_train, in_test]:\n",
    "    f = add_mean_median_std_per_factor\n",
    "    f(df, \"srch_id\", \"price_usd\", \"srch\")\n",
    "    f(df, \"srch_id\", \"prop_starrating\", \"srch\")\n",
    "    f(df, \"srch_id\", \"prop_review_score\", \"srch\")\n",
    "    \n",
    "    f(df, \"srch_destination_id\", \"price_usd\", \"dest\")\n",
    "    f(df, \"srch_destination_id\", \"prop_starrating\", \"dest\")\n",
    "    f(df, \"srch_destination_id\", \"prop_review_score\", \"dest\")\n",
    "    \n",
    "    f(df, \"prop_id\", \"price_usd\", \"prop\")\n",
    "    f(df, \"prop_id\", \"prop_review_score\", \"prop\")\n",
    "    \n",
    "print(\"Elapsed time\", (time.time() - start)/60)\n",
    "in_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time 13.447068818410237\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "def rank(s):\n",
    "    return pd.Series(scipy.stats.rankdata(s.fillna(-1)))\n",
    "\n",
    "# Add ranking of various features per query\n",
    "for df in [in_train, in_test]:\n",
    "    grouped = df.groupby(\"srch_id\")\n",
    "    df[\"srch_price_rank\"] = grouped.price_usd.apply(rank).reset_index(drop=True)\n",
    "    df[\"srch_star_rank\"] = grouped.prop_starrating.apply(rank).reset_index(drop=True)\n",
    "    df[\"srch_review_score_rank\"] = grouped.prop_review_score.apply(rank).reset_index(drop=True)\n",
    "    df[\"srch_location_score1_rank\"] = grouped.prop_location_score1.apply(rank).reset_index(drop=True)\n",
    "    df[\"srch_location_score2_rank\"] = grouped.prop_location_score2.apply(rank).reset_index(drop=True)\n",
    "    \n",
    "print(\"Elapsed time\", (time.time() - start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time 0.32132614056269326\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Split on search ids\n",
    "srch_ids = in_train[\"srch_id\"].unique()\n",
    "srch_ids_train, srch_ids_test_val = train_test_split(srch_ids, test_size=0.2, random_state = 42)\n",
    "srch_ids_test, srch_ids_val = train_test_split(srch_ids_test_val, test_size=0.5, random_state = 42)\n",
    "\n",
    "_train = in_train.loc[in_train.srch_id.isin(srch_ids_train)]\n",
    "_val = in_train.loc[in_train.srch_id.isin(srch_ids_val)]\n",
    "_test = in_train.loc[in_train.srch_id.isin(srch_ids_test)]\n",
    "\n",
    "print(\"Elapsed time\", (time.time() - start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#start = time.time()\n",
    "\n",
    "# Estimate probability of being clicked and booked\n",
    "#grouped = _train.groupby(\"prop_id\")    \n",
    "#click_prob_by_prop = grouped.click_bool.mean().to_dict()\n",
    "#book_prob_by_prop = grouped.booking_bool.mean().to_dict()\n",
    "\n",
    "#mean_click_prob = in_train.click_bool.mean()\n",
    "#mean_book_prob = in_train.booking_bool.mean()\n",
    "    \n",
    "#for df in [_train, _val, _test, in_test]:\n",
    "#    df[\"click_probability\"] = df.prop_id.map(lambda p: click_prob_by_prop.setdefault(p, mean_click_prob))\n",
    "#    df[\"booking_probability\"] = df.prop_id.map(lambda p: book_prob_by_prop.setdefault(p, mean_book_prob))\n",
    "    \n",
    "#    df.click_probability = (df.click_probability + mean_click_prob) / 2\n",
    "#    df.booking_probability = (df.booking_probability + mean_book_prob) / 2\n",
    "    \n",
    "#print(\"Elapsed time\", (time.time() - start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time 18.963125149408977\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Undersample a series so that there are as many non-clicked items as clicked and booked\n",
    "def downsample_series(s):\n",
    "    s1 = s.loc[s.click_bool == 1]\n",
    "    s2 = s.loc[s.click_bool == 0]\n",
    "    \n",
    "    if (len(s2) == 0):\n",
    "        return s1\n",
    "    \n",
    "    s2 = s2.sample(frac=min(1, len(s1)/len(s)))\n",
    "    return s1.append(s2).sort_index()\n",
    "\n",
    "_train_undersampled = _train.groupby(\"srch_id\").apply(downsample_series).reset_index(drop=True)\n",
    "\n",
    "print(\"Elapsed time\", (time.time() - start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time 9.21100804011027\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Save to CSV\n",
    "#_train.to_csv(\"data/processed/_train.csv\", index=False)\n",
    "_val.to_csv(\"data/processed/_val.csv\", index=False)\n",
    "_test.to_csv(\"data/processed/_test.csv\", index=False)\n",
    "_train_undersampled.to_csv(\"data/processed/_train_undersampled.csv\", index=False)\n",
    "in_test.to_csv(\"data/processed/kaggle_test.csv\", index=False)\n",
    "\n",
    "print(\"Elapsed time\", (time.time() - start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['srch_id', 'date_time', 'site_id', 'visitor_location_country_id',\n",
       "       'visitor_hist_starrating', 'visitor_hist_adr_usd', 'prop_country_id',\n",
       "       'prop_id', 'prop_starrating', 'prop_review_score', 'prop_brand_bool',\n",
       "       'prop_location_score1', 'prop_location_score2',\n",
       "       'prop_log_historical_price', 'price_usd', 'promotion_flag',\n",
       "       'srch_destination_id', 'srch_length_of_stay', 'srch_booking_window',\n",
       "       'srch_adults_count', 'srch_children_count', 'srch_room_count',\n",
       "       'srch_saturday_night_bool', 'srch_query_affinity_score',\n",
       "       'orig_destination_distance', 'random_bool', 'comp1_rate', 'comp1_inv',\n",
       "       'comp1_rate_percent_diff', 'comp2_rate', 'comp2_inv',\n",
       "       'comp2_rate_percent_diff', 'comp3_rate', 'comp3_inv',\n",
       "       'comp3_rate_percent_diff', 'comp4_rate', 'comp4_inv',\n",
       "       'comp4_rate_percent_diff', 'comp5_rate', 'comp5_inv',\n",
       "       'comp5_rate_percent_diff', 'comp6_rate', 'comp6_inv',\n",
       "       'comp6_rate_percent_diff', 'comp7_rate', 'comp7_inv',\n",
       "       'comp7_rate_percent_diff', 'comp8_rate', 'comp8_inv',\n",
       "       'comp8_rate_percent_diff', 'srch_mean_price_usd',\n",
       "       'srch_median_price_usd', 'srch_std_price_usd',\n",
       "       'srch_mean_prop_starrating', 'srch_median_prop_starrating',\n",
       "       'srch_std_prop_starrating', 'srch_mean_prop_review_score',\n",
       "       'srch_median_prop_review_score', 'srch_std_prop_review_score',\n",
       "       'dest_mean_price_usd', 'dest_median_price_usd', 'dest_std_price_usd',\n",
       "       'dest_mean_prop_starrating', 'dest_median_prop_starrating',\n",
       "       'dest_std_prop_starrating', 'dest_mean_prop_review_score',\n",
       "       'dest_median_prop_review_score', 'dest_std_prop_review_score',\n",
       "       'prop_mean_price_usd', 'prop_median_price_usd', 'prop_std_price_usd',\n",
       "       'prop_mean_prop_review_score', 'prop_median_prop_review_score',\n",
       "       'prop_std_prop_review_score', 'srch_price_rank', 'srch_star_rank',\n",
       "       'srch_review_score_rank', 'srch_location_score1_rank',\n",
       "       'srch_location_score2_rank'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPERIMENTAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "def parallel_apply(df, func):\n",
    "    chunks = np.array_split(df, cpu_count())\n",
    "    with Pool(cpu_count()) as p:\n",
    "        ret_list = p.map(func, chunks)\n",
    "    return pd.concat(ret_list).sort_index()\n",
    "\n",
    "def parallel_apply_grouped(grouped_df, func):\n",
    "    with Pool(cpu_count()) as p:\n",
    "        ret_list = p.map(func, [group for name, group in grouped_df])\n",
    "    return pd.concat(ret_list).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "def group_add_mean_median_std(df, numerical, prefix):\n",
    "    df[prefix + \"_mean_\" + numerical] = df[numerical].mean()\n",
    "    df[prefix + \"_median_\" + numerical] = df[numerical].median()\n",
    "    df[prefix + \"_std_\" + numerical] = df[numerical].std()\n",
    "\n",
    "def add_mean_median_std_per_factor(df, factor, numerical, prefix):\n",
    "    grouped = df.groupby(factor)\n",
    "    parallel_apply_grouped(grouped, group_add_mean_median_std)\n",
    "    \n",
    "for df in [in_train, in_test]:\n",
    "    f = add_mean_median_std_per_factor\n",
    "    f(df, \"srch_id\", \"price_usd\", \"srch\")\n",
    "    f(df, \"srch_id\", \"prop_starrating\", \"srch\")\n",
    "    f(df, \"srch_id\", \"prop_review_score\", \"srch\")\n",
    "    \n",
    "    f(df, \"srch_destination_id\", \"price_usd\", \"dest\")\n",
    "    f(df, \"srch_destination_id\", \"prop_starrating\", \"dest\")\n",
    "    f(df, \"srch_destination_id\", \"prop_review_score\", \"dest\")\n",
    "    \n",
    "    f(df, \"prop_id\", \"price_usd\", \"prop\")\n",
    "    f(df, \"prop_id\", \"prop_review_score\", \"prop\")\n",
    "    \n",
    "print(\"Elapsed time\", (time.time() - start)/60)\n",
    "in_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py35)",
   "language": "python",
   "name": "py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
